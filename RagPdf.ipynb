{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cyanj\\Code\\ragpdf\\rag_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "#loader = PyPDFLoader(\"752750_core_why_visual_analytics_whitepaper_0.pdf\")\n",
    "loader = PyPDFLoader(\"annual-report-2024.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    ")\n",
    "chunks = splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Free local embedding model (384-dim, fast, good quality)\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "#model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "model = ChatOllama(\n",
    "    model=\"llama3.2:1b\",      # or llama3.2:3b\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\":4})\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Answer based only on the following context. \n",
    "    If the context doesn't contain the answer, say \"I don't have that information\"\n",
    "    \n",
    "    Context: {context}\"\"\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "#def format_docs(docs):\n",
    "#    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\"Handle both Document objects AND dicts from retriever\"\"\"\n",
    "    texts = []\n",
    "    for doc in docs:\n",
    "        if hasattr(doc, 'page_content'):  # LangChain Document\n",
    "            texts.append(doc.page_content)\n",
    "        elif isinstance(doc, dict):       # Dict from retriever\n",
    "            texts.append(doc.get('page_content', str(doc)))\n",
    "        else:                             # Fallback\n",
    "            texts.append(str(doc))\n",
    "    return \"\\n\\n\".join(texts)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt | model | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer = rag_chain.invoke(\"What is the power of visual ai?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The company's total revenue for the year is not explicitly stated in the provided context. However, it can be inferred from the information given.\n",
      "\n",
      "At 1 January 2023:\n",
      "- Total comprehensive income for the year: $2,914,264\n",
      "- Profit for the year: -$617,917 (loss)\n",
      "- Cash flows from operating activities: $929,765\n",
      "\n",
      "This suggests that the company's revenue was not sufficient to cover its losses and cash outflows.\n",
      "\n",
      "At 31 December 2023:\n",
      "- Total comprehensive income for the year: $3,363,981\n",
      "- Profit for the year: -$697,767 (loss)\n",
      "- Cash flows from operating activities: $929,765\n",
      "\n",
      "This suggests that the company's revenue was sufficient to cover its losses and cash outflows.\n",
      "\n",
      "At 31 December 2024:\n",
      "- Total comprehensive income for the year: $3,781,548\n",
      "- Profit for the year: -$697,767 (loss)\n",
      "- Cash flows from operating activities: $929,765\n",
      "\n",
      "This suggests that the company's revenue was sufficient to cover its losses and cash outflows.\n",
      "\n",
      "Based on this information, it appears that the company's total revenue for each of the three years is:\n",
      "\n",
      "2023: Not explicitly stated\n",
      "2024: $2,837,424 (from 31 December)\n",
      "2025: $3,254,991 (from 31 December)\n",
      "\n",
      "Note that the revenue for 2023 is not provided in the context.\n"
     ]
    }
   ],
   "source": [
    "answer = rag_chain.invoke(\"What were the company's total revenues?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in rag_chain.stream(\"What were the main risk factors?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\"Convert ANYTHING to clean text\"\"\"\n",
    "    if not docs:\n",
    "        return \"\"\n",
    "    \n",
    "    texts = []\n",
    "    for item in docs:\n",
    "        if isinstance(item, dict):\n",
    "            content = item.get('page_content', '') or str(item)\n",
    "        elif hasattr(item, 'page_content'):\n",
    "            content = item.page_content\n",
    "        else:\n",
    "            content = str(item)\n",
    "        texts.append(content)\n",
    "    return \"\\n\\n\".join(texts)\n",
    "\n",
    "# Force retriever to return Documents\n",
    "def fix_retriever_output(docs):\n",
    "    if isinstance(docs, list):\n",
    "        return [Document(page_content=str(doc)) if not hasattr(doc, 'page_content') else doc for doc in docs]\n",
    "    return docs\n",
    "\n",
    "rag_chain_with_memory = (\n",
    "    {\n",
    "        \"context\": retriever | fix_retriever_output | format_docs,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"chat_history\": lambda x: chat_history\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "#rag_chain_with_memory = (\n",
    "#    {\n",
    "#        \"context\": retriever | format_docs,\n",
    "#        \"question\": RunnablePassthrough(),\n",
    "#        \"chat_history\": lambda x: chat_history  # Your chat_history object\n",
    "#    }\n",
    "#    | prompt\n",
    "#    | model\n",
    "#    | StrOutputParser()\n",
    "#)\n",
    "\n",
    "def ask(question): \n",
    "    response = rag_chain_with_memory.invoke(question)\n",
    "    chat_history.append(HumanMessage(content=question))\n",
    "    chat_history.append(AIMessage(content=response))\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The company's total revenue for the year is not explicitly stated in the provided context. However, it can be inferred from the information given.\n",
      "\n",
      "At 1 January 2023:\n",
      "- Total comprehensive income for the year: $2,914,264\n",
      "- Profit for the year: -$617,917 (loss)\n",
      "- Cash flows from operating activities: $929,765\n",
      "\n",
      "This suggests that the company's revenue was not sufficient to cover its losses and cash outflows.\n",
      "\n",
      "At 31 December 2023:\n",
      "- Total comprehensive income for the year: $3,363,981\n",
      "- Profit for the year: -$697,767 (loss)\n",
      "- Cash flows from operating activities: $929,765\n",
      "\n",
      "This suggests that the company's revenue was sufficient to cover its losses and cash outflows.\n",
      "\n",
      "At 31 December 2024:\n",
      "- Total comprehensive income for the year: $3,781,548\n",
      "- Profit for the year: -$697,767 (loss)\n",
      "- Cash flows from operating activities: $929,765\n",
      "\n",
      "This suggests that the company's revenue was sufficient to cover its losses and cash outflows.\n",
      "\n",
      "Based on this information, it appears that the company's total revenue for each of the three years is:\n",
      "\n",
      "2023: Not explicitly stated\n",
      "2024: $2,837,424 (from 31 December)\n",
      "2025: $3,254,991 (from 31 December)\n",
      "\n",
      "Note that the revenue for 2023 is not provided in the context.\n"
     ]
    }
   ],
   "source": [
    "print(ask(\"What were the company's total revenues?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no information about the previous year's financial statements in the provided context. The only information available is for this year, specifically the notes to the financial statements for the annual report 2024 of Prudential Singapore.\n"
     ]
    }
   ],
   "source": [
    "print(ask(\"How does that compare to last year?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ragpdf)",
   "language": "python",
   "name": "ragpdf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
